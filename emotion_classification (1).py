# -*- coding: utf-8 -*-
"""Emotion classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13mvU8NI7hb1m2jLh7x3ApPlCAs9x0KBc
"""

from google.colab import files
uploaded = files.upload()

pip install snscrape

import pandas as pd
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
import warnings
warnings.filterwarnings("ignore")

# --- Step 1: Load Dataset ---
df = pd.read_csv("/content/emotions.csv.zip")

# Balance dataset (optional but good for fairness)
min_count = 10000
df = (
    df.groupby('label', group_keys=False)
      .apply(lambda x: x.sample(min_count, random_state=42))
      .reset_index(drop=True)
)

# --- Step 2: Preprocessing ---
stopwords = set([
    'i','me','my','myself','we','our','you','your','yours','he','him','his','she','her',
    'it','its','they','them','their','what','which','who','this','that','these','those',
    'am','is','are','was','were','be','been','have','has','do','does','did','a','an','the',
    'and','but','if','or','because','as','until','while','of','at','by','for','with',
    'about','against','between','into','through','before','after','above','below','to',
    'from','up','down','in','out','on','off','over','under','again','further','then',
    'once','here','there','when','where','why','how','all','any','both','each','few','more',
    'most','other','some','such','no','nor','not','only','own','same','so','than','too',
    'very','s','t','can','will','just','don','should','now'
])

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+|@\w+|#\w+", '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    return ' '.join([word for word in text.split() if word not in stopwords])

df['clean_text'] = df['text'].apply(clean_text)

# --- Step 3: Vectorization ---
tfidf = TfidfVectorizer(max_features=1000)
X = tfidf.fit_transform(df['clean_text'])
y = df['label']

# --- Step 4: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Step 5: Try Different SVM Kernels ---
kernels = ['linear', 'rbf', 'poly', 'sigmoid']

for kernel in kernels:
    print(f"\nðŸ§ª Training with SVM Kernel: {kernel.upper()}")
    model = SVC(kernel=kernel)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… Accuracy: {acc:.4f}")
    print("ðŸ“Š Classification Report:")
    print(classification_report(y_test, y_pred))